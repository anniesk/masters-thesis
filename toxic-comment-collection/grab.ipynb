{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de515814-2ba8-4944-87ac-4c68642f4a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ousidhoum2019',\n",
       " 'mulki2019',\n",
       " 'mubarak2017twitter',\n",
       " 'mubarak2017aljazeera',\n",
       " 'davidson2017',\n",
       " 'gibert2018',\n",
       " 'gao2018',\n",
       " 'chung2019',\n",
       " 'qian2019',\n",
       " 'waseem2016',\n",
       " 'jha2017',\n",
       " 'elSherief2018',\n",
       " 'mandl2019en',\n",
       " 'mandl2019ger',\n",
       " 'mandl2019hind',\n",
       " 'bretschneider2017',\n",
       " 'ross2017',\n",
       " 'wiegand2018',\n",
       " 'pitenis2020',\n",
       " 'mathur2018',\n",
       " 'alfina2017',\n",
       " 'ibrohim2019',\n",
       " 'ibrohim2018',\n",
       " 'sanguinetti2018',\n",
       " 'fortuna2019',\n",
       " 'coltekin2019',\n",
       " 'albadi2018',\n",
       " 'basile2019',\n",
       " 'founta2018',\n",
       " 'wulczyn2017toxic',\n",
       " 'wulczyn2017aggressive',\n",
       " 'wulczyn2017attack',\n",
       " 'sigurbergsson2019',\n",
       " 'kulkarni2021',\n",
       " 'novak2021',\n",
       " 'kumar2018',\n",
       " 'zampieri2019',\n",
       " 'bretschneider2016wow',\n",
       " 'bretschneider2016lol']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toxic_comment_collection import datasets\n",
    "names = [d.name for d in datasets.get_datasets()]\n",
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2dd9eb-7016-4e7e-9188-ecf9bc1aca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ousidhoum2019\n",
      "ousidhoum2019 done\n",
      "mulki2019\n",
      "mulki2019 done\n",
      "mubarak2017twitter\n",
      "mubarak2017twitter done\n",
      "mubarak2017aljazeera\n",
      "mubarak2017aljazeera done\n",
      "davidson2017\n",
      "davidson2017 done\n",
      "gibert2018\n",
      "gibert2018 done\n",
      "gao2018\n",
      "gao2018 done\n",
      "chung2019\n",
      "chung2019 done\n",
      "qian2019\n",
      "WARNING: qian2019: Expected Dataset hash to be e2774f61af64942373e76e3928269bf6b7d8b41d5f5dcbcac9e760d4e93ef6b4 but was 7d086673ad4658db70414ba557f0c9ed3bef53c6081fbe1cd5e06f374847ba9e\n",
      "qian2019 done\n",
      "waseem2016\n",
      "waseem2016 done\n",
      "jha2017\n",
      "jha2017 done\n",
      "elSherief2018\n",
      "elSherief2018 done\n",
      "mandl2019en\n",
      "mandl2019en done\n",
      "mandl2019ger\n",
      "mandl2019ger done\n",
      "mandl2019hind\n",
      "mandl2019hind done\n",
      "bretschneider2017\n",
      "bretschneider2017 done\n",
      "ross2017\n",
      "ross2017 done\n",
      "wiegand2018\n",
      "wiegand2018 done\n",
      "pitenis2020\n",
      "WARNING: pitenis2020: Expected Dataset hash to be 4b1cbbcf1795b078d57640144b6cd72686b6e326dcc65e801799680f3a47bbb1 but was e813aa5da40b751e0d4302f2eaccf953ecd128b5878552c83580fda045d87399\n",
      "\n",
      "Error while processing pitenis2020. Continuing with next one.\n",
      "pitenis2020 failed\n",
      "mathur2018\n",
      "mathur2018 done\n",
      "alfina2017\n",
      "alfina2017 done\n",
      "ibrohim2019\n",
      "ibrohim2019 done\n",
      "ibrohim2018\n",
      "ibrohim2018 done\n",
      "sanguinetti2018\n",
      "sanguinetti2018 done\n",
      "fortuna2019\n",
      "fortuna2019 done\n",
      "coltekin2019\n",
      "coltekin2019 done\n",
      "albadi2018\n",
      "albadi2018 done\n",
      "basile2019\n",
      "basile2019 done\n",
      "founta2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:twarc:rate limit exceeded: sleeping 190.29180884361267 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "founta2018 done\n",
      "wulczyn2017toxic\n",
      "wulczyn2017toxic done\n",
      "wulczyn2017aggressive\n",
      "wulczyn2017aggressive done\n",
      "wulczyn2017attack\n",
      "wulczyn2017attack done\n",
      "sigurbergsson2019\n",
      "sigurbergsson2019 done\n",
      "kulkarni2021\n",
      "kulkarni2021 done\n",
      "novak2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:twarc:rate limit exceeded: sleeping 309.7767758369446 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novak2021 done\n",
      "kumar2018\n",
      "kumar2018 done\n",
      "zampieri2019\n",
      "zampieri2019 done\n",
      "bretschneider2016wow\n",
      "bretschneider2016wow done\n",
      "bretschneider2016lol\n",
      "bretschneider2016lol done\n"
     ]
    }
   ],
   "source": [
    "from toxic_comment_collection import get_dataset\n",
    "for n in names:\n",
    "    print(n)\n",
    "    try:\n",
    "        get_dataset(n,api_config_path='./src/toxic_comment_collection/api_config.json')\n",
    "    except:\n",
    "        print(n,\"failed\")\n",
    "        continue\n",
    "    print(n,\"done\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c3c9c-504c-49ad-90cc-bd525da1ad22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1931bff-8c43-4401-9bdb-37075cf7b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toxic_comment_collection import generate_statistics\n",
    "generate_statistics(\"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a7aa75-cee5-4022-b2d9-f20d98ce2086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [█████████████████████████████████████████---------] 82.1% Unify pitenis2020         \n",
      "Could not unify pitenis2020. Continuing with next dataset.\n",
      "Progress: [██████████████████████████████████████████████████] 100.0% Done                       \n",
      "Could not add pitenis2020gr.csv to the combined dataset. Continuing with next file.\n"
     ]
    }
   ],
   "source": [
    "from toxic_comment_collection import get_all_datasets\n",
    "get_all_datasets(config_path=\"./src/toxic_comment_collection/config.json\", skip_download=True, api_config_path='./src/toxic_comment_collection/api_config.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
